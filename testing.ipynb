{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Extract annotations from annotations_file_path and outputs it in out dir in yolo format\"\"\"\n",
    "\n",
    "import os.path\n",
    "from xml.dom import minidom\n",
    "\n",
    "out_dir = \"./out\"\n",
    "annotations_file_path = \"./annotations.xml\"\n",
    "\n",
    "# Constants\n",
    "label_dict = {\"cross\":0,\"circle\":1,\"triangle\":2,\"square\":3}\n",
    "bbox_type = tuple[int, int, int, int]\n",
    "\n",
    "def main():\n",
    "    # create out dir\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "\n",
    "    file = minidom.parse(annotations_file_path)\n",
    "    images = file.getElementsByTagName(\"image\")\n",
    "\n",
    "    for image in images:\n",
    "        width = int(image.getAttribute(\"width\"))\n",
    "        height = int(image.getAttribute(\"height\"))\n",
    "        name = os.path.splitext(image.getAttribute(\"name\"))[0]  # first ele is file name\n",
    "        bboxes = image.getElementsByTagName(\"box\")\n",
    "\n",
    "        with open(os.path.join(out_dir, name + \".txt\"), \"w\") as label_file:\n",
    "            # iterate over pairs of bbox and keypoints for every sperm\n",
    "            for bbox in bboxes:\n",
    "                class_index = label_dict[bbox.getAttribute(\"label\")]\n",
    "\n",
    "                xtl, ytl, xbr, ybr = prepare_bbox(bbox)\n",
    "\n",
    "                w = xbr - xtl\n",
    "                h = ybr - ytl\n",
    "                x_cen_norm = (xtl + (w / 2)) / width\n",
    "                y_cen_norm = (ytl + (h / 2)) / height\n",
    "                w_norm = w / width\n",
    "                h_norm = h / height\n",
    "\n",
    "                dataset_label = f\"{class_index} {x_cen_norm} {y_cen_norm} {w_norm} {h_norm} \"  # last space in str is necessary\n",
    "\n",
    "                dataset_label = dataset_label.rstrip() + \"\\n\"\n",
    "                label_file.write(dataset_label)\n",
    "\n",
    "    print(\"Finished writing all label files.\")\n",
    "\n",
    "\n",
    "def prepare_bbox(bbox: minidom.Element) -> bbox_type:\n",
    "    xtl = int(float(bbox.getAttribute(\"xtl\")))\n",
    "    ytl = int(float(bbox.getAttribute(\"ytl\")))\n",
    "    xbr = int(float(bbox.getAttribute(\"xbr\")))\n",
    "    ybr = int(float(bbox.getAttribute(\"ybr\")))\n",
    "    return xtl, ytl, xbr, ybr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = \"data/images/train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"runs/detect/train3/weights/last.pt\")\n",
    "shape_score_dict = {\"circle\":20,\"square\":15,\"triangle\":10,\"cross\":5}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(results):\n",
    "    score = 0\n",
    "    shapes_conversion_dict = results.names\n",
    "    for obj in map(int,results.cpu().boxes.cls.int()):\n",
    "        obj = int(obj)\n",
    "        shape = shapes_conversion_dict[obj]\n",
    "        score += shape_score_dict[shape]\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rtsp @ 0x55b961dfb080] Received packet without a start chunk; dropping frame.\n",
      "[rtsp @ 0x55b961dfb080] Received packet without a start chunk; dropping frame.\n",
      "[rtsp @ 0x55b961dfb080] Received packet without a start chunk; dropping frame.\n",
      "[rtsp @ 0x55b961dfb080] Received packet without a start chunk; dropping frame.\n",
      "[rtsp @ 0x55b961dfb080] Received packet without a start chunk; dropping frame.\n",
      "[rtsp @ 0x55b961dfb080] Received packet without a start chunk; dropping frame.\n",
      "[rtsp @ 0x55b961dfb080] Received packet without a start chunk; dropping frame.\n",
      "[rtsp @ 0x55b961dfb080] Received packet without a start chunk; dropping frame.\n",
      "[rtsp @ 0x55b961dfb080] Received packet without a start chunk; dropping frame.\n",
      "[rtsp @ 0x55b961dfb080] Received packet without a start chunk; dropping frame.\n",
      "[rtsp @ 0x55b961dfb080] Received packet without a start chunk; dropping frame.\n",
      "[rtsp @ 0x55b961dfb080] Received packet without a start chunk; dropping frame.\n",
      "[rtsp @ 0x55b961dfb080] Received packet without a start chunk; dropping frame.\n",
      "[rtsp @ 0x55b961dfb080] Received packet without a start chunk; dropping frame.\n",
      "[rtsp @ 0x55b961dfb080] Received packet without a start chunk; dropping frame.\n",
      "[rtsp @ 0x55b961dfb080] Received packet without a start chunk; dropping frame.\n",
      "[rtsp @ 0x55b961dfb080] Received packet without a start chunk; dropping frame.\n",
      "[rtsp @ 0x55b961dfb080] Received packet without a start chunk; dropping frame.\n",
      "\n",
      "0: 736x1280 8 crosss, 10 circles, 9 triangles, 8 squares, 91.7ms\n",
      "Speed: 5.2ms preprocess, 91.7ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 8 crosss, 10 circles, 9 triangles, 8 squares, 21.5ms\n",
      "Speed: 5.2ms preprocess, 21.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 8 crosss, 10 circles, 9 triangles, 8 squares, 21.5ms\n",
      "Speed: 3.2ms preprocess, 21.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 8 crosss, 10 circles, 9 triangles, 8 squares, 21.5ms\n",
      "Speed: 3.0ms preprocess, 21.5ms inference, 1.0ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 8 crosss, 10 circles, 9 triangles, 8 squares, 21.6ms\n",
      "Speed: 3.2ms preprocess, 21.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 8 crosss, 10 circles, 9 triangles, 8 squares, 21.5ms\n",
      "Speed: 3.1ms preprocess, 21.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 8 crosss, 10 circles, 9 triangles, 8 squares, 21.5ms\n",
      "Speed: 3.3ms preprocess, 21.5ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 8 crosss, 10 circles, 9 triangles, 8 squares, 19.3ms\n",
      "Speed: 3.3ms preprocess, 19.3ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 8 crosss, 10 circles, 9 triangles, 8 squares, 19.0ms\n",
      "Speed: 4.0ms preprocess, 19.0ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 8 crosss, 10 circles, 9 triangles, 8 squares, 19.3ms\n",
      "Speed: 3.2ms preprocess, 19.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 8 crosss, 10 circles, 9 triangles, 8 squares, 18.9ms\n",
      "Speed: 3.2ms preprocess, 18.9ms inference, 1.0ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 8 crosss, 10 circles, 9 triangles, 8 squares, 19.0ms\n",
      "Speed: 3.6ms preprocess, 19.0ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 8 crosss, 10 circles, 9 triangles, 8 squares, 18.9ms\n",
      "Speed: 3.2ms preprocess, 18.9ms inference, 0.9ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 8 crosss, 10 circles, 9 triangles, 8 squares, 19.1ms\n",
      "Speed: 3.6ms preprocess, 19.1ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 8 crosss, 10 circles, 9 triangles, 8 squares, 19.5ms\n",
      "Speed: 3.1ms preprocess, 19.5ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 8 crosss, 10 circles, 9 triangles, 8 squares, 19.1ms\n",
      "Speed: 3.3ms preprocess, 19.1ms inference, 1.0ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 8 crosss, 10 circles, 9 triangles, 8 squares, 19.0ms\n",
      "Speed: 3.7ms preprocess, 19.0ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 8 crosss, 10 circles, 9 triangles, 8 squares, 19.4ms\n",
      "Speed: 3.9ms preprocess, 19.4ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 8 crosss, 10 circles, 9 triangles, 8 squares, 18.9ms\n",
      "Speed: 2.8ms preprocess, 18.9ms inference, 1.0ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 8 crosss, 10 circles, 9 triangles, 8 squares, 19.1ms\n",
      "Speed: 3.7ms preprocess, 19.1ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 8 crosss, 10 circles, 9 triangles, 8 squares, 19.1ms\n",
      "Speed: 3.7ms preprocess, 19.1ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 8 crosss, 10 circles, 9 triangles, 8 squares, 19.0ms\n",
      "Speed: 3.6ms preprocess, 19.0ms inference, 1.0ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 8 crosss, 10 circles, 9 triangles, 8 squares, 19.4ms\n",
      "Speed: 4.5ms preprocess, 19.4ms inference, 1.0ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 8 crosss, 10 circles, 9 triangles, 8 squares, 19.0ms\n",
      "Speed: 4.3ms preprocess, 19.0ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 8 crosss, 10 circles, 9 triangles, 8 squares, 18.9ms\n",
      "Speed: 3.7ms preprocess, 18.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 8 crosss, 10 circles, 9 triangles, 8 squares, 19.4ms\n",
      "Speed: 3.0ms preprocess, 19.4ms inference, 1.0ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 8 crosss, 10 circles, 9 triangles, 8 squares, 19.0ms\n",
      "Speed: 3.8ms preprocess, 19.0ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 8 crosss, 10 circles, 9 triangles, 8 squares, 19.1ms\n",
      "Speed: 3.8ms preprocess, 19.1ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 8 crosss, 10 circles, 9 triangles, 8 squares, 19.3ms\n",
      "Speed: 3.2ms preprocess, 19.3ms inference, 1.0ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 8 crosss, 10 circles, 9 triangles, 8 squares, 18.9ms\n",
      "Speed: 3.4ms preprocess, 18.9ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 8 crosss, 10 circles, 9 triangles, 8 squares, 19.3ms\n",
      "Speed: 3.4ms preprocess, 19.3ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 8 crosss, 10 circles, 9 triangles, 8 squares, 19.0ms\n",
      "Speed: 3.2ms preprocess, 19.0ms inference, 1.0ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 8 crosss, 10 circles, 9 triangles, 8 squares, 18.9ms\n",
      "Speed: 3.8ms preprocess, 18.9ms inference, 1.0ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"rtsp://192.168.1.102:8554/unicast\")\n",
    "scores = []\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    results = model(frame,conf=0.5,show=False)\n",
    "    scores.append(calculate_score(results[0]))\n",
    "    if len(scores) == 50:\n",
    "        scores.pop(0)\n",
    "    score = np.median(scores)\n",
    "    img = results[0].plot(labels=False)\n",
    "    cv2.putText(img, f\"Score: {score}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    cv2.imshow('det',img)\n",
    "    if cv2.waitKey(1) == ord('d'):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_detection(img):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    lower_black = np.array([0, 0, 0], dtype=np.uint8)\n",
    "    upper_black = np.array([255, 200, 255], dtype=np.uint8)\n",
    "    black_mask = cv2.inRange(hsv, lower_black, upper_black)\n",
    "    # black_detected = cv2.bitwise_and(img, img, mask=black_mask)\n",
    "    return black_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_name in os.listdir(\"shapes_pics\"):\n",
    "    img_path = os.path.join(\"shapes_pics\",img_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    # crop left half of image\n",
    "    img = img[65:-60,int(img.shape[1]/2)+150:]\n",
    "    orig = np.array(img)\n",
    "    cv2.imwrite(os.path.join(\"out\",img_name),img)\n",
    "    # img = black_detection(img)\n",
    "#     cv2.imshow('orig',cv2.resize(orig,None,fx=0.5,fy=0.5))\n",
    "#     # cv2.imshow('img',cv2.resize(img,None,fx=0.5,fy=0.5))\n",
    "#     if cv2.waitKey(0)&0xff == ord('d'):\n",
    "#         break\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[tcp @ 0x55bfeb822b00] Connection to tcp://10.10.221.34:8080 failed: No route to host\n",
      "[ERROR:0@1004.016] global cap.cpp:164 open VIDEOIO(CV_IMAGES): raised OpenCV exception:\n",
      "\n",
      "OpenCV(4.8.0) /io/opencv/modules/videoio/src/cap_images.cpp:253: error: (-5:Bad argument) CAP_IMAGES: can't find starting number (in the name of file): https://10.10.221.34:8080/unicast in function 'icvExtractPattern'\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m/home/omarabdelgawad/my_workspace/projects/ROV_work/shapes_task/testing.ipynb Cell 10\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/omarabdelgawad/my_workspace/projects/ROV_work/shapes_task/testing.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/omarabdelgawad/my_workspace/projects/ROV_work/shapes_task/testing.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     ret, frame \u001b[39m=\u001b[39m cap\u001b[39m.\u001b[39mread()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/omarabdelgawad/my_workspace/projects/ROV_work/shapes_task/testing.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     frame \u001b[39m=\u001b[39m black_detection(frame)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/omarabdelgawad/my_workspace/projects/ROV_work/shapes_task/testing.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     cv2\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39mdet\u001b[39m\u001b[39m'\u001b[39m,frame)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/omarabdelgawad/my_workspace/projects/ROV_work/shapes_task/testing.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mif\u001b[39;00m cv2\u001b[39m.\u001b[39mwaitKey(\u001b[39m1\u001b[39m) \u001b[39m==\u001b[39m \u001b[39mord\u001b[39m(\u001b[39m'\u001b[39m\u001b[39md\u001b[39m\u001b[39m'\u001b[39m):\n",
      "\u001b[1;32m/home/omarabdelgawad/my_workspace/projects/ROV_work/shapes_task/testing.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/omarabdelgawad/my_workspace/projects/ROV_work/shapes_task/testing.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mblack_detection\u001b[39m(img):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/omarabdelgawad/my_workspace/projects/ROV_work/shapes_task/testing.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     hsv \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mcvtColor(img, cv2\u001b[39m.\u001b[39;49mCOLOR_BGR2HLS)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/omarabdelgawad/my_workspace/projects/ROV_work/shapes_task/testing.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     lower_black \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39muint8)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/omarabdelgawad/my_workspace/projects/ROV_work/shapes_task/testing.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     upper_black \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39m255\u001b[39m, \u001b[39m200\u001b[39m, \u001b[39m255\u001b[39m], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39muint8)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "# capture atef's video stream\n",
    "cap = cv2.VideoCapture(\"rtsp://:8080/unicast\")\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    frame = black_detection(frame)\n",
    "    cv2.imshow('det',frame)\n",
    "    if cv2.waitKey(1) == ord('d'):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
